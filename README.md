# Udacity_connect

This repo contains a collection of Jupyter Notebooks to accompany the Udacity Connect Intensive [Machine Learning Nanodegree](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009). The code is written for Python 2.7, but should be (mostly) compatible with Python 3.  

## List of Contents 
- Week 1 (`wk1/`)  
	- `PythonPractice_1.ipynb`: Introduction to Jupyter Notebook and basic Python programming (including data types, if and while loops, list comprehension, lambda expression, etc.).    
	- `PythonPractice_2.ipynb`: Introduction to Numpy, including how to create Numpy Array, built-in methods in Numpy array, array indexing/selection/slicing, broadcasting.   
	- `PythonPractice_3.ipynb`: Introduction to Pandas. Topics include inputting data into DataFrame and getting summary information, selection and indexing, conditional selection with DataFrame, etc.  
	- `PythonPractice_4.ipynb`: Introduction to data visualization with Matplotlib and Seaborn.  
	- `data/`: containing one sample dataset for the notebooks and one for exercise.  

- Week 2 (`wk2/`)  
	- `SklearnTutorial.ipynb`: Introduction to scikit-learn (`sklearn`) and a step-by-step guide of building a machine learning model with `sklearn` with the Titanic Survival dataset from Kaggle
	- `SklearnTutorial-solution.ipynb`: The solution to the `SklearnTutorial.ipynb` notebook.

- Week 3 (`wk3/`)  
	- `RegressionModels.ipynb`: Introduction to the implementation and evaluatoin of regression models to predict housing price with `sklearn`.    
	- `RegressionModels-solution.ipynb`: The solution to the `RegressionModels.ipynb`

- Week 4 (`wk4/`)  
	- `NeuralNets_Miniproject.ipynb`: Introduction to the fundamentals of neural networks, the implementation of single layer and multi layer perceptrons, and perceptron with `scikit-learn`.    
	- `NeuralNets_Miniproject-solution.ipynb`: The solution to the `NeuralNets_Miniproject.ipynb` notebook. 

- Week 5 (`wk5/`)  
	- `BayesNLP_Miniproject.ipynb`: Introduction to Bayes theorem and application of Bayes theorem in natual language processing. Write Python methods to calculate maximum likelihood of a word based on the preceding word, and build a Bayes classifier that computes with a context the optimal label for a second missing word based on the possible words that could be in the first blank.    
	- `BayesNLP_Miniproject-solution.ipynb`: The solution to the `BayesNLP_Miniproject.ipynb` notebook. 
	- `Quiz.pdf`: some quiz on supervised learning. 

